<html>

<head>
	<title>Coded Bias - Review & Commentary</title>
	<meta name="title" content="Movie review - Coded Bias">
	<meta name="image"
		content="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5e1fd277f64941c26c2eaffc_Coded-Bias.jpg">
	<meta name="description"
		content="Coded Bias is a great watch for everyone looking up to Ai as the future of technology to be able to think responsibly, but it has some glaring issues...">
	<meta name="tags" content="tec, ent"> <!-- tec, art, fit, sdg, ent -->
	<meta name="date" content="7th July 2021">
	<link rel="stylesheet" href="../article_styles.css" />
</head>

<body class="article-full-view">
	<h2>Coded Bias - Informative Misguidance</h2>
	<small id="publishDate">Date: 7th July 2021</small>
	<p>
		I just watched the movie called <a href="https://en.wikipedia.org/wiki/Coded_Bias">"Coded Bias"</a>, directed by
		<a href="https://en.wikipedia.org/wiki/Shalini_Kantayya">Shalini Kantayya</a> as an assignment for an
		open-source summer training program conducted by <a href="https://dgplug.org/">#dgplug</a>. Before I start, I
		want to mention that I have been studying and practising AI (Artificial Intelligence, which consists of
		algorithmic programs that can perform intelligent actions) and ML (Machine Learning, a set of algorithms which
		learns from data and modifies its output based on training) for more than 7 years now. I have assumed the role
		of a data scientist for multiple companies, as an employee or as a consultant and am a strong proponent of AI
		and ML in consumer products for the betterment of society.
		I would also like to mention that this is a technical review. I will not be talking about the artistic aspects
		of the movie/documentary, apart from the fact that I thoroughly enjoyed watching it but my parents left the
		living room in less than 10 minutes. So clearly it is entertaining for a very niche audience.
	</p>
	<p>
		I have been reading about XAI (Explainable Artificial Intelligence) for a long time and have friends who have
		published on the topic of fairness of ML models from the day I started my professional life in 2016.
		So I was already aware of the problem itself, but this movie was still very informative for me. It was like
		going through the history of how was this problem identified. The protagonist of the story, a black woman named
		Joy, has clearly created a tremendous impact in the way ML and AI are perceived and how responsibility in AI has
		become a popular theme for conversation nowadays.
	</p>
	<p>
		I was really moved by the observation of Amazon retaliating the research with baseless points, when I had quite
		some respect of the American company for their people-skills. And I really liked IBM's response of accommodating
		the feedback about the bias into their models. IBM really gained some respect points in my eyes through this
		documentary.
		The remark that "By learning about the current state of the world and automating it, we will be forever stuck in
		the present, never making progress" was especially noteworthy for me. I will make my best effort to not fall
		into this trap whenever I build another AI product.
	</p>
	<p>
		Another aspect of the documentary which was very informative for me was the focus on privacy related to facial
		recognition and surveillance. There are a few points that I want to touch upon here:
	<ul>
		<li> I learnt a little bit about the dangers of free service of data to centralized authorities, like the
			government or corporations like Facebook, Google and Amazon. The immediate ones, as well as the ones that
			come as a consequence. Specially noting the experience of the young impactful black woman facing probation
			related suspicion, who noted that the actions arising from the suspicion will later lead to the suspicion
			turning true </li>
		<li> I learnt about the actual implementation of the Chinese social credit system. To be honest, their society
			seemed far superior to me. I still hold advancement and convinience above privacy. I just want it to be done
			in a transparent and open manner, so that it leads to more freedom, not less. And I liked the fact that they
			showed the positive opinion of the Chinese women about the Chinese system, but didn't like the fact that
			they tried to make that portion of the movie boring, devoid of any English commentary. It seemed that the
			director herself was biased towards her own opinion, while her conscience wanted to be just and fair.</li>
		<li>I loved to hear the perspectives of the people who were subjected to too much surveillance and how there was
			discrimination even in the application of the surveillance -- more surveillance for low income minorities
			versus the high-income majority populations.</li>
	</ul>
	</p>
	<p>
		What I did not like was the action that was demanded and implemented as a preventive measure. Banning the use of
		advanced technology altogether is not going to help the society. The focus should never have turned to banning,
		instead it should be focussed on regulating it.
		This movie was referred by an open-source evangelist group, which, for me, leads to an obvious solution to the
		problem. Keep the data and the models public if the model is ever going to affect a person's life negatively or
		sharply reduce the number of opportunities for them.
		And even otherwise, I expected Joy, who herself went to MIT for the love for robotics, to not downplay the role
		of hi-tech in the society, and rather find a way to make it benefit the society instead of hurting it.
		AI and ML are tools, like any other. They can be used for better or worse. Just like anything else, be it a
		knife, fire, or a communication medium, its impact is only amplification of what its users are trying to
		achieve. Although I do agree, that currently there is an imbalance of power rising due to the accessibility to
		such technology. I believe <a href="https://openai.com/">OpenAI</a> and other organizations and initiatives that
		it inspired will help us tackle that.
	</p>
	<p>
		I specifically hated the fact that they were inappropriately using the very well defined term "Algorithm". They
		were grossly generalizing ML algorithms to say that the programmers themselves do not completely understand what
		their algorithms do. We do. We know exactly what our programs as doing, as long as their is no machine learning
		involved. And believe me, the majority of the algorithms in deployment are not learning from data.
		I also disliked when Joy let a senators remarks pass, when she tried to associate the bias in the performance of
		facial recognition algorithms to the developers of those algorithms. First of all, Joy has no way of knowing who
		the developers were. Most probably it consisted of more brown and yellow skinned people than white skinned, but
		I don't want to get into that. Secondly, being educated about ML, Joy should have pointed out to the senator
		that the bias is not due to the programmers, but due the data. That would probably have led to a more fruitful
		decision.
	</p>

	<div class="article-controls">
		<a class="back-to-list" href="/blog">‚Üê Back to Articles</a>
	</div>
</body>
<script src="../article.js"></script>

</html>