<html>
<head>
	<title>Coded Bias - Review & Commentary</title>
	<meta name="title" content="Movie review - Coded Bias">
	<meta name="image" content="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5e1fd277f64941c26c2eaffc_Coded-Bias.jpg">
	<meta name="description" content="Coded Bias is a great watch for everyone looking up to Ai as the future of technology to be able to think responsibly, but it has some glaring issues...">
	<meta name="tags" content="tec, ent"> <!-- tec, art, fit, sdg, ent -->
	<meta name="date" content="7th July 2021">
</head>
<body style="width:90%">
	<h2>Coded Bias - Informative Misguidance</h2>
	<small id="publishDate">Date: 7th July 2021</small>
	<p>
		I just watched the movie called <a href="https://en.wikipedia.org/wiki/Coded_Bias">"Coded Bias"</a>, directed by <a href="https://en.wikipedia.org/wiki/Shalini_Kantayya">Shalini Kantayya</a> as an assignment for an open-source summer training program conducted by <a href="https://dgplug.org/">#dgplug</a>. Before I start, I want to mention that I have been studying and practising AI (Artificial Intelligence, which consists of algorithmic programs that can perform intelligent actions) and ML (Machine Learning, a set of algorithms which learns from data and modifies its output based on training) for more than 7 years now. I have assumed the role of a data scientist for multiple companies, as an employee or as a consultant and am a strong proponent of AI and ML in consumer products for the betterment of society.
		I would also like to mention that this is a technical review. I will not be talking about the artistic aspects of the movie/documentary, apart from the fact that I thoroughly enjoyed watching it but my parents left the living room in less than 10 minutes. So clearly it is entertaining for a very niche audience.
	</p>
	<p>
		I have been reading about XAI (Explainable Artificial Intelligence) for a long time and have friends who have published on the topic of fairness of ML models from the day I started my professional life in 2016.
		So I was already aware of the problem itself, but this movie was still very informative for me. It was like going through the history of how was this problem identified. The protagonist of the story, a black woman named Joy, has clearly created a tremendous impact in the way ML and AI are perceived and how responsibility in AI has become a popular theme for conversation nowadays.
	</p>
	<p>
		I was really moved by the observation of Amazon retaliating the research with baseless points, when I had quite some respect of the American company for their people-skills. And I really liked IBM's response of accommodating the feedback about the bias into their models. IBM really gained some respect points in my eyes through this documentary.
		The remark that "By learning about the current state of the world and automating it, we will be forever stuck in the present, never making progress" was especially noteworthy for me. I will make my best effort to not fall into this trap whenever I build another AI product.
	</p>
	<p>
		Another aspect of the documentary which was very informative for me was the focus on privacy related to facial recognition and surveillance. There are a few points that I want to touch upon here:
		<ul>
			<li> I learnt a little bit about the dangers of free service of data to centralized authorities, like the government or corporations like Facebook, Google and Amazon. The immediate ones, as well as the ones that come as a consequence. Specially noting the experience of the young impactful black woman facing probation related suspicion, who noted that the actions arising from the suspicion will later lead to the suspicion turning true </li>
			<li> I learnt about the actual implementation of the Chinese social credit system. To be honest, their society seemed far superior to me. I still hold advancement and convinience above privacy. I just want it to be done in a transparent and open manner, so that it leads to more freedom, not less. And I liked the fact that they showed the positive opinion of the Chinese women about the Chinese system, but didn't like the fact that they tried to make that portion of the movie boring, devoid of any English commentary. It seemed that the director herself was biased towards her own opinion, while her conscience wanted to be just and fair.</li>
			<li>I loved to hear the perspectives of the people who were subjected to too much surveillance and how there was discrimination even in the application of the surveillance -- more surveillance for low income minorities versus the high-income majority populations.</li>
		</ul>
	</p>
	<p>
		What I did not like was the action that was demanded and implemented as a preventive measure. Banning the use of advanced technology altogether is not going to help the society. The focus should never have turned to banning, instead it should be focussed on regulating it.
		This movie was referred by an open-source evangelist group, which, for me, leads to an obvious solution to the problem. Keep the data and the models public if the model is ever going to affect a person's life negatively or sharply reduce the number of opportunities for them.
		And even otherwise, I expected Joy, who herself went to MIT for the love for robotics, to not downplay the role of hi-tech in the society, and rather find a way to make it benefit the society instead of hurting it.
		AI and ML are tools, like any other. They can be used for better or worse. Just like anything else, be it a knife, fire, or a communication medium, its impact is only amplification of what its users are trying to achieve. Although I do agree, that currently there is an imbalance of power rising due to the accessibility to such technology. I believe <a href="https://openai.com/">OpenAI</a> and other organizations and initiatives that it inspired will help us tackle that.
	</p>
	<p>
		I specifically hated the fact that they were inappropriately using the very well defined term "Algorithm". They were grossly generalizing ML algorithms to say that the programmers themselves do not completely understand what their algorithms do. We do. We know exactly what our programs as doing, as long as their is no machine learning involved. And believe me, the majority of the algorithms in deployment are not learning from data.
		I also disliked when Joy let a senators remarks pass, when she tried to associate the bias in the performance of facial recognition algorithms to the developers of those algorithms. First of all, Joy has no way of knowing who the developers were. Most probably it consisted of more brown and yellow skinned people than white skinned, but I don't want to get into that. Secondly, being educated about ML, Joy should have pointed out to the senator that the bias is not due to the programmers, but due the data. That would probably have led to a more fruitful decision.
	</p>
</body>
<script src="../article.js"></script>
</html>
